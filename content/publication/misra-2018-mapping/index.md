---
title: Mapping Instructions to Actions in 3D Environments with Visual Goal Prediction
date: '2018-11-03'
draft: false
publishDate: '2018-11-03T05:42:43.351259Z'
authors:
- Dipendra Misra
- Andrew Bennett
- Valts Blukis
- Eyvind Niklasson
- Max Shatkhin
- Yoav Artzi
publication_types:
- 1
abstract: '''
    We propose to decompose instruction execution to goal prediction and
    action generation. We design a model that maps raw visual observations
    to goals using LINGUNET, a language-conditioned image generation network,
    and then generates the actions required to complete them. Our model is
    trained from demonstration only without external resources. To evaluate
    our approach, we introduce two benchmarks for instruction following:
    LANI, a navigation task; and CHAI, where an agent executes household
    instructions. Our evaluation demonstrates the advantages of our model
    decomposition, and illustrates the challenges posed by our new
    benchmarks.'''
featured: false
publication: '*Conference on Empirical Methods in Natural Language Processing (EMNLP)*'
url_pdf: https://aclanthology.org/D18-1287.pdf

---


